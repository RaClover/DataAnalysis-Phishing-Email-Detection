{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**imports several libraries and modules for text processing, data manipulation, and email handling. **","metadata":{}},{"cell_type":"code","source":"#import several libraries and modules for text processing, data manipulation, and email handling.\nimport re\nimport os\nimport nltk\nimport string\nimport mailbox\nimport pandas as pd\nfrom bs4 import BeautifulSoup\nfrom collections import Counter\nfrom nltk.corpus import stopwords\nfrom email.header import decode_header\nfrom nltk.tokenize import word_tokenize","metadata":{"execution":{"iopub.status.busy":"2023-05-24T03:28:58.761061Z","iopub.execute_input":"2023-05-24T03:28:58.761526Z","iopub.status.idle":"2023-05-24T03:28:58.767593Z","shell.execute_reply.started":"2023-05-24T03:28:58.761486Z","shell.execute_reply":"2023-05-24T03:28:58.766346Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#containing phishing emails. \nphishing_emails = mailbox.mbox('/kaggle/input/phishingemaildetection/emails-phishing-nazario.mbox')\n#mbox containing valid emails. \nvalid_emails = mailbox.mbox('/kaggle/input/phishingemaildetection/emails-enron-legal-mails.mbox')","metadata":{"execution":{"iopub.status.busy":"2023-05-24T03:28:58.769499Z","iopub.execute_input":"2023-05-24T03:28:58.769765Z","iopub.status.idle":"2023-05-24T03:28:58.791998Z","shell.execute_reply.started":"2023-05-24T03:28:58.769739Z","shell.execute_reply":"2023-05-24T03:28:58.791110Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# EmailParser is used to parse email messages and extract various information from them. \nclass EmailParser:\n    urlRegex = r'https?:\\/\\/(?:www\\.)?[-a-zA-Z0-9@:%._\\+~#=]{1,256}\\.[a-zA-Z0-9()]{1,6}\\b(?:[-a-zA-Z0-9()@:%_\\+.~#?&\\/=;]*)'\n    emailRegex = r'([a-zA-Z0-9._-]+@[a-zA-Z0-9._-]+\\.[a-zA-Z0-9_-]+)'\n    \n# This is the constructor method of the class. It takes an email parameter and initializes the instance variables\n    def __init__(self, email):\n        self.email = email\n        self.__extract_email_parts()\n        \n#This method iterates over the parts of the email message using the walk() method.\n#It checks the content type of each part and based on that,\n#extracts the text, HTML content, and counts the number of attachments.\n\n    def __extract_email_parts(self):\n        no_of_attachments = 0\n        text = str(self.email['Subject']) + \" \"\n        htmlDoc = \"\"\n        for part in self.email.walk():\n            content_type = part.get_content_type()\n            if content_type == 'text/plain':\n                text += str(part.get_payload())\n            elif content_type == 'text/html':\n                htmlDoc += part.get_payload()\n            else:\n                main_content_type = part.get_content_maintype()\n                if main_content_type in ['image','application']:\n                    no_of_attachments += 1\n        self.text, self.html, self.no_of_attachments = text, htmlDoc, no_of_attachments\n        \n #This method returns a list of URLs found in both the text and HTML content of the email.\n #It uses regular expressions and the urlRegex class variable to match and extract URLs from the text and HTML.  \n    \n    def get_urls(self):\n        text_urls = set(re.findall(EmailParser.urlRegex,self.text))\n        html_urls = set(re.findall(EmailParser.urlRegex,self.html))\n        return list(text_urls.union(html_urls))\n    \n    #This method returns the text content of the email. If HTML content is present\n    def get_email_text(self):\n        if(self.html != \"\"):\n            soup = BeautifulSoup(self.html)\n            self.text += soup.text\n        return self.text\n    \n    #This method returns the number of attachments found in the email\n    def get_no_of_attachments(self):\n        return self.no_of_attachments\n    \n    #This method returns the email address of the sender. \n    #It retrieves the sender's information from the email parameter passed to the constructor.\n    def get_sender_email_address(self):\n        sender = email['From']\n        try:\n            emails = re.findall(EmailParser.emailRegex, sender)\n        except:\n            h = decode_header(email['From'])\n            header_bytes = h[0][0]\n            sender = header_bytes.decode('ISO-8859-1')\n            emails = re.findall(EmailParser.emailRegex, sender)\n        if(len(emails) != 0):\n            return emails[len(emails)-1]\n        else:\n            return ''\n    ","metadata":{"execution":{"iopub.status.busy":"2023-05-24T03:28:58.793616Z","iopub.execute_input":"2023-05-24T03:28:58.794124Z","iopub.status.idle":"2023-05-24T03:28:58.805827Z","shell.execute_reply.started":"2023-05-24T03:28:58.794093Z","shell.execute_reply":"2023-05-24T03:28:58.804719Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#provide various utility methods for processing text, URLs, and email addresses\nclass StringUtil:\n    \n    dotRegex = r'\\.'\n    digitsRegex = r'[0-9]'\n    ipAddressRegex = r'(?:[0-9]{1,3}\\.){3}[0-9]{1,3}'\n    dashesRegex = r'-'\n    specialCharsRegex = r'[()@:%_\\+~#?\\=;]'\n    words = Counter()\n    stop_words = set(stopwords.words('english'))\n    stemmer = nltk.PorterStemmer()\n    punctuations = ['!','@','#','$','%','^','&','*','(',')','-','_','=','+',';',':',\"'\",'\"','?','/','<','>','.',',','/','~','`']\n    \n    \n    #This method takes a list of URLs as input and processes them. \n    #It counts the number of dots, dashes, and special characters in each URL\n    def process_urls(self,urls):\n        noOfDots, noOfDashes, noOfSpecialChars, hasIpAddressInUrl, noOfIpAddress, noOfHttpsLinks = 0,0,0,0,0,0\n        for url in urls:\n            if url.startswith('https://'):\n                noOfHttpsLinks += 1\n            noOfDots += len(re.findall(StringUtil.dotRegex,url))\n            noOfDashes += len(re.findall(StringUtil.dashesRegex,url))\n            noOfSpecialChars += len(re.findall(StringUtil.specialCharsRegex,url))\n            noOfIpAddress += len(re.findall(StringUtil.ipAddressRegex, url))\n        if noOfIpAddress > 0:\n            hasIpAddressInUrl = 1\n        return len(urls), noOfDots, noOfDashes, noOfSpecialChars, hasIpAddressInUrl, noOfIpAddress, noOfHttpsLinks\n    \n    \n    #This method takes a string of text as input and processes it. It performs several operations on the text, including converting it to lowercase, \n    #removing escape sequences, removing punctuation and digits, tokenizing the text into individual words\n    def process_text(self, text):\n        text = text.lower()                    #lowercase\n        text = re.sub(r'[\\n\\t\\r]', ' ', text)  #remove escape sequences \n        \n        #remove punctuations\n        punctuation = string.punctuation  # Get all punctuation marks\n        translator = str.maketrans('', '', punctuation + string.digits)  # Create a translator to remove punctuation and digits\n        text = text.translate(translator)  # Remove punctuation and digits using translate()\n\n        #tokenize and stem words\n        word_tokens = word_tokenize(text)\n        filtered_text = []\n        for w in word_tokens:\n            if w not in StringUtil.stop_words:\n                filtered_text.append(w)\n        \n        #count frequency of words\n        word_counts = Counter(filtered_text)\n        stemmed_word_count = Counter()\n        for word, count in word_counts.items():\n            stemmed_word = StringUtil.stemmer.stem(word)\n            stemmed_word_count[stemmed_word] += count\n        word_counts = stemmed_word_count\n        StringUtil.words += word_counts\n        return word_counts\n    \n    #This method takes an email address as input and processes it. It calculates various metrics related to the email address, \n    #including its length, the counts of dots, dashes, special characters, digits, and subdomains\n    def process_email_address(self, emailid):\n        length, noOfDots, noOfDashes, noOfSpecialChars, noOfDigits, noOfSubdomains = 0,0,0,0,0,0\n        \n        length = len(emailid)\n        if(length > 0):\n            username, domain = emailid.split('@')\n            noOfSubdomains = len(re.findall(StringUtil.dotRegex,domain)) - 1\n            noOfDots = len(re.findall(StringUtil.dotRegex, username))\n            noOfSpecialChars = len(re.findall(StringUtil.specialCharsRegex, username))\n            noOfDashes = len(re.findall(StringUtil.dashesRegex, emailid))\n            noOfDigits = len(re.findall(StringUtil.digitsRegex, emailid))\n        \n        return length, noOfDots, noOfDashes, noOfSpecialChars, noOfDigits, noOfSubdomains\n        \n        #This method returns the 1000 most common words encountered so far in the text processing. \n        #It accesses the class variable StringUtil.words, \n        #which is a Counter object that keeps track of word frequencies across all processed texts.\n    def get_most_common_words(self):\n        return StringUtil.words.most_common(1000)","metadata":{"execution":{"iopub.status.busy":"2023-05-24T03:28:58.807362Z","iopub.execute_input":"2023-05-24T03:28:58.807734Z","iopub.status.idle":"2023-05-24T03:28:58.828232Z","shell.execute_reply.started":"2023-05-24T03:28:58.807697Z","shell.execute_reply":"2023-05-24T03:28:58.827191Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#StringUtil class and the EmailParser class to process a list of phishing emails and extract relevant features. \n#It then adds the extracted features along with the corresponding class label to a pandas DataFrame named df1\n\ndf1 =pd.DataFrame(columns=['text', 'lengthOfEmailId', 'noOfDotsInEmailId', 'noOfDashesInEmailId', 'noOfSpecialCharsInEmailId', 'noOfDigitsInEmailId', 'noOfSubdomainsInEmailId', 'noOfUrls', 'noOfDotsInUrls', 'noOfDashesInUrls', 'noOfSpecialCharsInUrls', 'hasIpAddressInUrls', 'noOfIpAddressInUrls', 'noOfHttpsLinks','no_of_attachments','class_label'])\nstringUtil = StringUtil()\nfor email in phishing_emails:\n    emailParser = EmailParser(email)\n    no_of_attachments = emailParser.get_no_of_attachments()\n    emailid_features = stringUtil.process_email_address(emailParser.get_sender_email_address())\n    urls_features = stringUtil.process_urls(emailParser.get_urls())\n    word_dict = stringUtil.process_text(emailParser.get_email_text())\n    df1.loc[len(df1)] = [word_dict, emailid_features[0], emailid_features[1], emailid_features[2], emailid_features[3], emailid_features[4], emailid_features[5], urls_features[0],urls_features[1],urls_features[2],urls_features[3],urls_features[4],urls_features[5], urls_features[6], no_of_attachments, 1]\n\n#get most common words from phishing emails\nmalicious_words = stringUtil.get_most_common_words()","metadata":{"execution":{"iopub.status.busy":"2023-05-24T03:28:58.831018Z","iopub.execute_input":"2023-05-24T03:28:58.831865Z","iopub.status.idle":"2023-05-24T03:29:26.849435Z","shell.execute_reply.started":"2023-05-24T03:28:58.831831Z","shell.execute_reply":"2023-05-24T03:29:26.848324Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df1.head()","metadata":{"execution":{"iopub.status.busy":"2023-05-24T03:29:26.850592Z","iopub.execute_input":"2023-05-24T03:29:26.850895Z","iopub.status.idle":"2023-05-24T03:29:26.878960Z","shell.execute_reply.started":"2023-05-24T03:29:26.850862Z","shell.execute_reply":"2023-05-24T03:29:26.877821Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#shows the usage of the StringUtil class and the EmailParser class to process a list of valid emails and extract relevant features. \n#It then adds the extracted features along with the corresponding class label to a new pandas DataFrame named\n\ndf2 =pd.DataFrame(columns=['text', 'lengthOfEmailId', 'noOfDotsInEmailId', 'noOfDashesInEmailId', 'noOfSpecialCharsInEmailId', 'noOfDigitsInEmailId', 'noOfSubdomainsInEmailId', 'noOfUrls', 'noOfDotsInUrls', 'noOfDashesInUrls', 'noOfSpecialCharsInUrls', 'hasIpAddressInUrls', 'noOfIpAddressInUrls', 'noOfHttpsLinks','no_of_attachments','class_label'])\nstringUtil = StringUtil()\nfor email in valid_emails:\n    emailParser = EmailParser(email)\n    no_of_attachments = emailParser.get_no_of_attachments()\n    emailid_features = stringUtil.process_email_address(emailParser.get_sender_email_address())\n    urls_features = stringUtil.process_urls(emailParser.get_urls())\n    word_dict = stringUtil.process_text(emailParser.get_email_text())\n    df2.loc[len(df2)] = [word_dict, emailid_features[0], emailid_features[1], emailid_features[2], emailid_features[3], emailid_features[4], emailid_features[5], urls_features[0],urls_features[1],urls_features[2],urls_features[3],urls_features[4],urls_features[5], urls_features[6], no_of_attachments, 0]","metadata":{"execution":{"iopub.status.busy":"2023-05-24T03:29:26.880241Z","iopub.execute_input":"2023-05-24T03:29:26.880977Z","iopub.status.idle":"2023-05-24T03:30:26.504070Z","shell.execute_reply.started":"2023-05-24T03:29:26.880951Z","shell.execute_reply":"2023-05-24T03:30:26.503004Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df2.head()","metadata":{"execution":{"iopub.status.busy":"2023-05-24T03:30:26.505716Z","iopub.execute_input":"2023-05-24T03:30:26.506027Z","iopub.status.idle":"2023-05-24T03:30:26.527329Z","shell.execute_reply.started":"2023-05-24T03:30:26.505998Z","shell.execute_reply":"2023-05-24T03:30:26.525968Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.concat([df1,df2],axis=0)","metadata":{"execution":{"iopub.status.busy":"2023-05-24T03:30:26.528564Z","iopub.execute_input":"2023-05-24T03:30:26.528825Z","iopub.status.idle":"2023-05-24T03:30:26.539002Z","shell.execute_reply.started":"2023-05-24T03:30:26.528801Z","shell.execute_reply":"2023-05-24T03:30:26.538084Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#adds a new column to the DataFrame df named 'noOfMaliciousWords'\n#and populates it with the count of malicious words present in each email. \n#It then removes the 'text' column from the DataFrame.\n\ndf['noOfMaliciousWords'] = df['text'].apply(lambda x: len(set(x.keys()).intersection(set(dict(malicious_words).keys()))))\ndf = df.drop(columns=['text'])","metadata":{"execution":{"iopub.status.busy":"2023-05-24T03:30:26.541033Z","iopub.execute_input":"2023-05-24T03:30:26.541332Z","iopub.status.idle":"2023-05-24T03:30:27.233354Z","shell.execute_reply.started":"2023-05-24T03:30:26.541307Z","shell.execute_reply":"2023-05-24T03:30:27.232490Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2023-05-24T03:30:27.236472Z","iopub.execute_input":"2023-05-24T03:30:27.236872Z","iopub.status.idle":"2023-05-24T03:30:27.257179Z","shell.execute_reply.started":"2023-05-24T03:30:27.236837Z","shell.execute_reply":"2023-05-24T03:30:27.256016Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2023-05-24T03:30:27.258937Z","iopub.execute_input":"2023-05-24T03:30:27.259319Z","iopub.status.idle":"2023-05-24T03:30:27.284589Z","shell.execute_reply.started":"2023-05-24T03:30:27.259261Z","shell.execute_reply":"2023-05-24T03:30:27.283236Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = df.astype('int')","metadata":{"execution":{"iopub.status.busy":"2023-05-24T03:30:27.286200Z","iopub.execute_input":"2023-05-24T03:30:27.286514Z","iopub.status.idle":"2023-05-24T03:30:27.296401Z","shell.execute_reply.started":"2023-05-24T03:30:27.286476Z","shell.execute_reply":"2023-05-24T03:30:27.295575Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2023-05-24T03:30:27.297221Z","iopub.execute_input":"2023-05-24T03:30:27.298259Z","iopub.status.idle":"2023-05-24T03:30:27.314250Z","shell.execute_reply.started":"2023-05-24T03:30:27.298214Z","shell.execute_reply":"2023-05-24T03:30:27.313184Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score, precision_score\n\n\nx = df.drop(columns=[\"class_label\"]).values\ny = df[\"class_label\"].values\n\nx_train, x_test, y_train, y_test = train_test_split(x, y, random_state=34, test_size=0.2)","metadata":{"execution":{"iopub.status.busy":"2023-05-24T03:30:27.316317Z","iopub.execute_input":"2023-05-24T03:30:27.316676Z","iopub.status.idle":"2023-05-24T03:30:27.353935Z","shell.execute_reply.started":"2023-05-24T03:30:27.316647Z","shell.execute_reply":"2023-05-24T03:30:27.352826Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = RandomForestClassifier()\nmodel.fit(x_train, y_train)\n\ny_pred = model.predict(x_test)\n\n# This line calculates and prints the prediction accuracy of the model by comparing the predicted labels y_pred \n#with the true labels y_test using the accuracy_score() function from sklearn.metrics.\n#The accuracy score represents the proportion of correctly predicted labels.\nprint('Prediction accuracy: ', accuracy_score(y_test, y_pred))\n\n# This line calculates and prints the precision score of the model by comparing the predicted labels y_pred \n#with the true labels y_test using the precision_score() function from sklearn.metrics.\n#The precision score represents the ability of the classifier to correctly identify positive instances.\nprint('Precision Score: ', precision_score(y_test, y_pred))\n","metadata":{"execution":{"iopub.status.busy":"2023-05-24T03:30:27.355117Z","iopub.execute_input":"2023-05-24T03:30:27.356014Z","iopub.status.idle":"2023-05-24T03:30:27.739569Z","shell.execute_reply.started":"2023-05-24T03:30:27.355872Z","shell.execute_reply":"2023-05-24T03:30:27.738456Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}